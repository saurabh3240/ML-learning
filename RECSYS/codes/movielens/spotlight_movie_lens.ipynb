{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://github.com/maciejkula/spotlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "from spotlight.evaluation import rmse_score\n",
    "from spotlight.factorization.explicit import ExplicitFactorizationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Interactions dataset (944 users x 1683 items x 100000 interactions)>\n"
     ]
    }
   ],
   "source": [
    "dataset = get_movielens_dataset(variant='100K')\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExplicitFactorizationModel(loss='regression',\n",
    "                                   embedding_dim=128,  # latent dimensionality\n",
    "                                   n_iter=10,  # number of epochs of training\n",
    "                                   batch_size=1024,  # minibatch size\n",
    "                                   l2=1e-9,  # strength of L2 regularization\n",
    "                                   learning_rate=1e-3,\n",
    "                                   use_cuda=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into \n",
      " <Interactions dataset (944 users x 1683 items x 80000 interactions)> and \n",
      " <Interactions dataset (944 users x 1683 items x 20000 interactions)>.\n"
     ]
    }
   ],
   "source": [
    "train, test = random_train_test_split(dataset, random_state=np.random.RandomState(42))\n",
    "\n",
    "print('Split into \\n {} and \\n {}.'.format(train, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sysadmin\\Anaconda3\\lib\\site-packages\\spotlight\\factorization\\explicit.py:237: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  epoch_loss += loss.data[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 13.098525047302246\n",
      "Epoch 1: loss 7.324594020843506\n",
      "Epoch 2: loss 1.7548301219940186\n",
      "Epoch 3: loss 1.0716947317123413\n",
      "Epoch 4: loss 0.9445939660072327\n",
      "Epoch 5: loss 0.8987710475921631\n",
      "Epoch 6: loss 0.8789787888526917\n",
      "Epoch 7: loss 0.8615714907646179\n",
      "Epoch 8: loss 0.8535652756690979\n",
      "Epoch 9: loss 0.8428651690483093\n"
     ]
    }
   ],
   "source": [
    "model.fit(train, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE 0.905, test RMSE 0.944\n"
     ]
    }
   ],
   "source": [
    "train_rmse = rmse_score(model, train)\n",
    "test_rmse = rmse_score(model, test)\n",
    "\n",
    "\n",
    "print('Train RMSE {:.3f}, test RMSE {:.3f}'.format(train_rmse, test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Interactions dataset (944 users x 1683 items x 80000 interactions)>\n",
      "218\n",
      "[0.12084319 3.5884275  2.970261   ... 1.5114372  1.7241297  1.7488763 ]\n",
      "(4.25579, 408)\n",
      "408\n"
     ]
    }
   ],
   "source": [
    "print(train)\n",
    "uid = test.user_ids[2]\n",
    "print(uid)\n",
    "preds = model.predict(uid)\n",
    "print(preds)\n",
    "\n",
    "F = [(preds[i],i) for i in range(len(preds))]\n",
    "print(max(F))\n",
    "z,x = max(F)\n",
    "print(x)\n",
    "movie_name = dataset.item_ids[x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_check',\n",
       " 'item_ids',\n",
       " 'num_items',\n",
       " 'num_users',\n",
       " 'ratings',\n",
       " 'timestamps',\n",
       " 'to_sequence',\n",
       " 'tocoo',\n",
       " 'tocsr',\n",
       " 'user_ids',\n",
       " 'weights']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
